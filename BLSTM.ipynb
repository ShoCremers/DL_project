{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "prerequisite-subscription",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup dependencies (as taken from assignment 6)\n",
    "import os\n",
    "import math\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "#Additional Setup to use Tensorboard\n",
    "!pip install -q tensorflow\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "premium-equipment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day-ahead Price [EUR/MWh]</th>\n",
       "      <th>tempC</th>\n",
       "      <th>windspeedKmph</th>\n",
       "      <th>winddirDegree</th>\n",
       "      <th>precipMM</th>\n",
       "      <th>humidity</th>\n",
       "      <th>pressure</th>\n",
       "      <th>time_increment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-05 00:00:00</th>\n",
       "      <td>-0.243620</td>\n",
       "      <td>-1.722376</td>\n",
       "      <td>-0.422598</td>\n",
       "      <td>0.563889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.96</td>\n",
       "      <td>2.163731</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-05 01:00:00</th>\n",
       "      <td>-0.316395</td>\n",
       "      <td>-1.722376</td>\n",
       "      <td>-0.297098</td>\n",
       "      <td>0.572222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.96</td>\n",
       "      <td>2.058525</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-05 02:00:00</th>\n",
       "      <td>-0.439933</td>\n",
       "      <td>-1.722376</td>\n",
       "      <td>-0.171598</td>\n",
       "      <td>0.580556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.96</td>\n",
       "      <td>2.058525</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-05 03:00:00</th>\n",
       "      <td>-0.625914</td>\n",
       "      <td>-1.722376</td>\n",
       "      <td>-0.046098</td>\n",
       "      <td>0.588889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.953318</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-05 04:00:00</th>\n",
       "      <td>-0.626363</td>\n",
       "      <td>-1.722376</td>\n",
       "      <td>-0.171598</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.953318</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31 19:00:00</th>\n",
       "      <td>0.877205</td>\n",
       "      <td>-1.130468</td>\n",
       "      <td>-0.673599</td>\n",
       "      <td>0.602778</td>\n",
       "      <td>0.054545</td>\n",
       "      <td>0.94</td>\n",
       "      <td>-1.728907</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31 20:00:00</th>\n",
       "      <td>0.665169</td>\n",
       "      <td>-1.130468</td>\n",
       "      <td>-0.422598</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>0.93</td>\n",
       "      <td>-1.728907</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31 21:00:00</th>\n",
       "      <td>0.469755</td>\n",
       "      <td>-1.130468</td>\n",
       "      <td>-0.171598</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.054545</td>\n",
       "      <td>0.93</td>\n",
       "      <td>-1.623701</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31 22:00:00</th>\n",
       "      <td>0.443699</td>\n",
       "      <td>-1.278445</td>\n",
       "      <td>-0.422598</td>\n",
       "      <td>0.747222</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>0.92</td>\n",
       "      <td>-1.413288</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31 23:00:00</th>\n",
       "      <td>0.461668</td>\n",
       "      <td>-1.426422</td>\n",
       "      <td>-0.673599</td>\n",
       "      <td>0.847222</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.91</td>\n",
       "      <td>-1.308081</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52512 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Day-ahead Price [EUR/MWh]     tempC  windspeedKmph  \\\n",
       "datetime                                                                  \n",
       "2015-01-05 00:00:00                  -0.243620 -1.722376      -0.422598   \n",
       "2015-01-05 01:00:00                  -0.316395 -1.722376      -0.297098   \n",
       "2015-01-05 02:00:00                  -0.439933 -1.722376      -0.171598   \n",
       "2015-01-05 03:00:00                  -0.625914 -1.722376      -0.046098   \n",
       "2015-01-05 04:00:00                  -0.626363 -1.722376      -0.171598   \n",
       "...                                        ...       ...            ...   \n",
       "2020-12-31 19:00:00                   0.877205 -1.130468      -0.673599   \n",
       "2020-12-31 20:00:00                   0.665169 -1.130468      -0.422598   \n",
       "2020-12-31 21:00:00                   0.469755 -1.130468      -0.171598   \n",
       "2020-12-31 22:00:00                   0.443699 -1.278445      -0.422598   \n",
       "2020-12-31 23:00:00                   0.461668 -1.426422      -0.673599   \n",
       "\n",
       "                     winddirDegree  precipMM  humidity  pressure  \\\n",
       "datetime                                                           \n",
       "2015-01-05 00:00:00       0.563889  0.000000      0.96  2.163731   \n",
       "2015-01-05 01:00:00       0.572222  0.000000      0.96  2.058525   \n",
       "2015-01-05 02:00:00       0.580556  0.000000      0.96  2.058525   \n",
       "2015-01-05 03:00:00       0.588889  0.000000      0.96  1.953318   \n",
       "2015-01-05 04:00:00       0.575000  0.000000      0.96  1.953318   \n",
       "...                            ...       ...       ...       ...   \n",
       "2020-12-31 19:00:00       0.602778  0.054545      0.94 -1.728907   \n",
       "2020-12-31 20:00:00       0.625000  0.036364      0.93 -1.728907   \n",
       "2020-12-31 21:00:00       0.650000  0.054545      0.93 -1.623701   \n",
       "2020-12-31 22:00:00       0.747222  0.036364      0.92 -1.413288   \n",
       "2020-12-31 23:00:00       0.847222  0.018182      0.91 -1.308081   \n",
       "\n",
       "                     time_increment  \n",
       "datetime                             \n",
       "2015-01-05 00:00:00             2.4  \n",
       "2015-01-05 01:00:00             0.1  \n",
       "2015-01-05 02:00:00             0.2  \n",
       "2015-01-05 03:00:00             0.3  \n",
       "2015-01-05 04:00:00             0.4  \n",
       "...                             ...  \n",
       "2020-12-31 19:00:00             1.9  \n",
       "2020-12-31 20:00:00             2.0  \n",
       "2020-12-31 21:00:00             2.1  \n",
       "2020-12-31 22:00:00             2.2  \n",
       "2020-12-31 23:00:00             2.3  \n",
       "\n",
       "[52512 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('day_ahead.csv')\n",
    "df = df.set_index('datetime')\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "english-beast",
   "metadata": {},
   "source": [
    "# Create Torch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "recognized-aging",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequence length (edit the value for different sequence length)\n",
    "seq = 36 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "velvet-thunder",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = pd.Timedelta(seq, unit ='h')\n",
    "# define 1 hour object for convenience when using datetime as index in the dataframe to not include the last item\n",
    "hours_12 = pd.Timedelta(12, unit ='h') # used mostly for empty 12 hours \n",
    "hour = pd.Timedelta(1, unit ='h')\n",
    "day = pd.Timedelta(1, unit ='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "flush-crawford",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2155, 36, 8)\n",
      "(2155, 24)\n"
     ]
    }
   ],
   "source": [
    "### creating training dataset\n",
    "train_y_start = dt.datetime(2015, 1, 5, 0, 0) + (delta+hours_12).ceil('1d')\n",
    "#train_x_start = train_y_start - delta - hours_12\n",
    "train_end = dt.datetime(2020, 11, 30, 23, 0)\n",
    "\n",
    "train_x = []\n",
    "train_y = []\n",
    "while train_y_start + day - hour <= train_end:\n",
    "    train_x_start = train_y_start - delta - hours_12\n",
    "    \n",
    "    \n",
    "    #print(train_x_start, train_y_start)\n",
    "    train_x.append(df[train_x_start:train_x_start+delta - hour].values)\n",
    "    train_y.append(df[train_y_start:train_y_start+day - hour]['Day-ahead Price [EUR/MWh]'].values)\n",
    "    \n",
    "    train_y_start += day\n",
    "    \n",
    "train_x = np.asarray(train_x)\n",
    "train_y = np.asarray(train_y)\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "demanding-copyright",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 36, 8)\n",
      "(31, 24)\n"
     ]
    }
   ],
   "source": [
    "### creating testing dataset\n",
    "test_y_start = dt.datetime(2020, 12, 1, 0, 0)\n",
    "test_end = dt.datetime(2020, 12, 31, 23, 0)\n",
    "\n",
    "test_x = []\n",
    "test_y = []\n",
    "while test_y_start + day - hour <= test_end:\n",
    "    test_x_start = test_y_start - delta - hours_12\n",
    "    \n",
    "    test_x.append(df[test_x_start:test_x_start+delta - hour].values)\n",
    "    test_y.append(df[test_y_start:test_y_start+day - hour]['Day-ahead Price [EUR/MWh]'].values)\n",
    "    \n",
    "    test_y_start += day\n",
    "\n",
    "test_x = np.asarray(test_x)\n",
    "test_y = np.asarray(test_y)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "taken-somalia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tensor objects\n",
    "x_train = torch.from_numpy(train_x).float()\n",
    "y_train = torch.from_numpy(train_y).float()\n",
    "x_test = torch.from_numpy(test_x).float()\n",
    "y_test = torch.from_numpy(test_y).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "muslim-blame",
   "metadata": {},
   "source": [
    "# Define BLSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "rural-activation",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n",
    "        super(BLSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(hidden_dim*2, output_dim) # multiply hidden_dim by 2 because bidirectional\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_dim).requires_grad_() #hidden layer output\n",
    "        # Initialize cell state\n",
    "        c0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_dim).requires_grad_() \n",
    "        # We need to detach as we are doing truncated backpropagation through time (BPTT)\n",
    "        # If we don't, we'll backprop all the way to the start even after going through another batch\n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "        # Index hidden state of last time step\n",
    "        out = self.fc(out[:, -1, :]) \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fuzzy-thompson",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "automated-valuation",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = x_train.shape[0]\n",
    "input_dim = x_train.shape[2]\n",
    "output_dim = 24 \n",
    "hidden_dim = 20 # no. of neurons in hidden layer\n",
    "num_layers = 3 # no of hidden layers \n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "special-bahamas",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BLSTM(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, num_layers=num_layers)\n",
    "# for practice use MSE, in real experiment use NLLLOSS for parametric\n",
    "criterion = nn.MSELoss(reduction='mean')\n",
    "#criterion = nn.NLLLoss()\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "favorite-reunion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0 MSE:  0.6251276288942159\n",
      "Epoch  1 MSE:  0.6146098782790267\n",
      "Epoch  2 MSE:  0.6003325983874388\n",
      "Epoch  3 MSE:  0.5674329914341696\n",
      "Epoch  4 MSE:  0.5604366081684672\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-1e328c3be620>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0my_train_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0moptimiser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pytorch-cpu/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-1dc2f379b4f2>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# We need to detach as we are doing truncated backpropagation through time (BPTT)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# If we don't, we'll backprop all the way to the start even after going through another batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mh0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0;31m# Index hidden state of last time step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pytorch-cpu/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/pytorch-cpu/lib/python3.8/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    659\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[1;32m    662\u001b[0m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m    663\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "for t in range(num_epochs): \n",
    "    err = 0\n",
    "    for i in range(num_train):\n",
    "        y_train_pred = model(x_train[i].unsqueeze(0))\n",
    "        loss = criterion(y_train_pred, y_train[i])\n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        err += loss.item()\n",
    "        #print(\"item \", t, \"MSE: \", loss.item())\n",
    "        \n",
    "    print(\"Epoch \", t, \"MSE: \", err/num_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thrown-welcome",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scheduled-checkout",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "static-bulgaria",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training old loop\n",
    "for t in range(num_epochs): \n",
    "    \n",
    "    y_train_pred = model(x_train)\n",
    "    loss = criterion(y_train_pred, y_train)\n",
    "    print(\"Epoch \", t, \"MSE: \", loss.item())\n",
    "    optimiser.zero_grad()\n",
    "    loss.backward()\n",
    "    optimiser.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filled-tucson",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-mapping",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decent-mobility",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dangerous-european",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "included-committee",
   "metadata": {},
   "source": [
    "## NLLLoss example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "least-meeting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[2, 1, 2, 0, 1, 3, 2, 0],\n",
      "         [0, 2, 0, 2, 2, 1, 3, 3],\n",
      "         [1, 2, 0, 3, 1, 0, 2, 3],\n",
      "         [0, 2, 2, 3, 1, 1, 3, 1],\n",
      "         [3, 0, 3, 1, 2, 3, 2, 0],\n",
      "         [3, 1, 2, 0, 3, 0, 3, 0],\n",
      "         [2, 1, 0, 1, 3, 0, 3, 2],\n",
      "         [2, 0, 3, 1, 1, 1, 0, 3]],\n",
      "\n",
      "        [[3, 2, 2, 2, 2, 3, 3, 1],\n",
      "         [2, 1, 1, 3, 0, 1, 2, 0],\n",
      "         [3, 1, 0, 2, 0, 1, 3, 0],\n",
      "         [3, 2, 3, 0, 1, 3, 0, 3],\n",
      "         [3, 3, 2, 1, 3, 3, 0, 2],\n",
      "         [3, 1, 1, 0, 1, 2, 3, 2],\n",
      "         [2, 1, 3, 1, 2, 1, 0, 1],\n",
      "         [3, 3, 0, 0, 2, 1, 0, 0]],\n",
      "\n",
      "        [[2, 0, 0, 1, 0, 0, 0, 0],\n",
      "         [2, 1, 2, 3, 0, 1, 2, 1],\n",
      "         [2, 0, 2, 1, 2, 3, 3, 2],\n",
      "         [0, 1, 2, 0, 0, 2, 0, 2],\n",
      "         [0, 0, 3, 3, 3, 1, 1, 1],\n",
      "         [2, 0, 3, 2, 1, 3, 1, 3],\n",
      "         [1, 1, 1, 0, 2, 0, 1, 0],\n",
      "         [1, 3, 1, 1, 3, 3, 0, 3]],\n",
      "\n",
      "        [[3, 1, 2, 2, 3, 2, 1, 2],\n",
      "         [1, 1, 3, 0, 1, 1, 2, 0],\n",
      "         [0, 1, 2, 0, 3, 2, 2, 2],\n",
      "         [2, 3, 3, 0, 0, 3, 0, 0],\n",
      "         [1, 0, 0, 3, 1, 0, 1, 3],\n",
      "         [2, 0, 2, 3, 0, 3, 3, 3],\n",
      "         [3, 3, 3, 1, 3, 3, 3, 3],\n",
      "         [1, 3, 2, 0, 1, 2, 0, 3]],\n",
      "\n",
      "        [[3, 0, 1, 0, 2, 2, 1, 1],\n",
      "         [3, 1, 2, 1, 3, 0, 2, 3],\n",
      "         [1, 1, 0, 0, 0, 1, 3, 0],\n",
      "         [3, 0, 0, 1, 0, 2, 0, 0],\n",
      "         [0, 3, 0, 2, 0, 0, 0, 3],\n",
      "         [2, 3, 2, 0, 3, 2, 2, 0],\n",
      "         [2, 3, 2, 2, 3, 3, 3, 3],\n",
      "         [2, 1, 2, 0, 2, 3, 1, 1]]])\n",
      "tensor([[[[-1.5799, -2.2298, -1.7663,  ..., -2.5805, -1.5235, -2.0852],\n",
      "          [-2.0149, -1.5811, -1.3034,  ..., -1.8099, -1.8595, -1.5067],\n",
      "          [-1.8114, -1.1468, -1.7413,  ..., -1.8268, -1.5492, -1.0224],\n",
      "          ...,\n",
      "          [-2.2783, -1.6601, -2.0226,  ..., -1.9272, -1.3910, -1.2628],\n",
      "          [-2.4322, -1.5577, -1.4399,  ..., -1.7150, -1.4426, -1.6930],\n",
      "          [-1.7724, -1.0611, -1.8907,  ..., -1.9827, -1.4242, -0.9681]],\n",
      "\n",
      "         [[-1.7116, -1.5714, -1.1580,  ..., -1.8631, -1.3872, -1.5731],\n",
      "          [-1.3183, -1.3072, -1.0916,  ..., -0.8708, -2.2917, -1.7433],\n",
      "          [-0.7441, -1.6039, -0.9255,  ..., -0.8905, -1.8267, -1.9704],\n",
      "          ...,\n",
      "          [-0.8594, -1.2365, -1.0338,  ..., -1.0768, -1.2370, -1.9425],\n",
      "          [-1.7273, -1.7905, -1.4521,  ..., -1.1245, -1.4804, -0.7189],\n",
      "          [-1.5875, -1.3253, -1.5641,  ..., -0.4135, -1.4188, -1.3311]],\n",
      "\n",
      "         [[-2.1150, -0.6071, -0.8027,  ..., -1.2442, -1.1514, -1.6067],\n",
      "          [-1.4031, -1.4506, -1.7074,  ..., -1.3509, -1.0038, -1.5563],\n",
      "          [-1.9276, -1.9952, -1.5375,  ..., -1.5642, -1.8624, -1.4656],\n",
      "          ...,\n",
      "          [-1.1870, -1.1366, -1.6038,  ..., -1.4184, -0.9317, -1.0947],\n",
      "          [-0.7235, -2.1542, -0.9886,  ..., -0.9153, -0.7545, -2.0106],\n",
      "          [-1.0569, -1.9235, -1.3255,  ..., -2.2086, -1.1459, -2.0563]],\n",
      "\n",
      "         [[-0.7077, -1.9676, -2.7061,  ..., -0.7321, -1.5320, -0.7598],\n",
      "          [-1.0406, -1.2405, -1.5542,  ..., -1.8407, -0.9763, -0.9352],\n",
      "          [-1.5328, -1.0634, -1.5444,  ..., -1.5169, -0.7522, -1.3096],\n",
      "          ...,\n",
      "          [-1.7778, -1.6165, -1.1683,  ..., -1.3032, -2.7023, -1.4306],\n",
      "          [-1.3890, -0.6802, -1.8524,  ..., -2.3557, -2.7199, -1.6356],\n",
      "          [-1.2797, -1.4185, -0.9832,  ..., -2.3952, -1.6126, -1.4780]]],\n",
      "\n",
      "\n",
      "        [[[-1.4577, -1.9206, -1.5695,  ..., -1.8885, -0.6584, -1.2193],\n",
      "          [-1.2551, -2.0675, -1.6257,  ..., -2.1013, -2.1312, -1.5981],\n",
      "          [-1.5483, -1.5360, -1.9996,  ..., -2.1860, -0.5912, -1.2086],\n",
      "          ...,\n",
      "          [-1.6114, -1.4793, -1.6508,  ..., -1.7174, -2.5050, -2.2185],\n",
      "          [-1.1832, -0.9856, -1.0652,  ..., -1.9242, -1.9210, -1.4067],\n",
      "          [-2.1544, -1.1153, -1.0892,  ..., -1.1174, -1.3302, -1.4839]],\n",
      "\n",
      "         [[-1.1961, -1.4550, -1.3244,  ..., -0.7572, -2.0957, -2.1674],\n",
      "          [-1.2579, -0.5146, -1.1226,  ..., -2.0341, -1.5756, -1.6252],\n",
      "          [-1.8589, -1.4992, -1.3243,  ..., -1.2825, -1.5820, -1.1440],\n",
      "          ...,\n",
      "          [-2.2753, -1.6549, -1.0534,  ..., -1.7403, -0.9622, -1.5307],\n",
      "          [-1.6694, -1.6403, -1.5605,  ..., -1.5096, -2.3045, -0.7966],\n",
      "          [-1.2547, -1.9199, -2.0748,  ..., -1.5311, -1.2217, -1.6850]],\n",
      "\n",
      "         [[-1.4981, -1.4495, -1.3976,  ..., -1.7401, -1.4048, -0.7718],\n",
      "          [-1.8048, -1.7235, -0.9211,  ..., -1.2697, -1.3681, -1.1591],\n",
      "          [-1.3194, -0.8224, -0.8046,  ..., -1.4631, -2.3660, -1.8076],\n",
      "          ...,\n",
      "          [-0.8429, -0.6676, -1.3721,  ..., -0.9053, -1.3042, -0.7754],\n",
      "          [-1.1043, -2.0064, -1.3273,  ..., -0.8807, -1.0865, -1.5698],\n",
      "          [-2.2524, -1.8070, -0.9455,  ..., -1.8673, -1.1171, -0.6884]],\n",
      "\n",
      "         [[-1.4218, -0.9535, -1.2776,  ..., -1.5886, -2.1721, -2.0564],\n",
      "          [-1.3235, -2.3299, -2.5293,  ..., -0.7636, -0.8679, -1.2481],\n",
      "          [-1.0099, -2.1031, -1.8880,  ..., -0.9708, -1.9179, -1.5196],\n",
      "          ...,\n",
      "          [-1.3199, -2.6858, -1.5811,  ..., -1.4247, -1.3284, -1.5403],\n",
      "          [-1.7493, -1.2093, -1.7142,  ..., -1.5210, -0.8762, -2.3422],\n",
      "          [-0.7058, -1.0177, -1.9007,  ..., -1.1972, -2.1748, -2.4603]]],\n",
      "\n",
      "\n",
      "        [[[-1.1526, -0.6341, -1.1577,  ..., -1.8911, -2.3090, -1.7036],\n",
      "          [-1.1565, -1.4645, -1.2042,  ..., -0.5916, -2.2711, -1.7646],\n",
      "          [-1.9763, -1.0096, -1.3936,  ..., -1.8535, -1.4752, -1.4703],\n",
      "          ...,\n",
      "          [-1.1222, -1.5219, -1.6311,  ..., -1.9554, -0.9884, -1.4628],\n",
      "          [-0.7991, -1.8846, -1.5414,  ..., -2.0246, -1.3332, -1.9281],\n",
      "          [-1.2409, -1.8217, -0.9385,  ..., -1.4743, -1.7613, -2.0493]],\n",
      "\n",
      "         [[-1.0276, -1.1344, -1.8210,  ..., -2.2303, -0.9768, -1.4766],\n",
      "          [-1.3952, -0.9930, -0.9062,  ..., -2.7810, -0.4702, -0.5763],\n",
      "          [-0.8464, -1.1450, -1.4482,  ..., -1.1649, -1.6452, -1.0023],\n",
      "          ...,\n",
      "          [-1.5009, -2.2675, -0.7467,  ..., -2.6924, -1.1756, -1.1550],\n",
      "          [-1.6283, -0.9962, -1.2351,  ..., -3.1427, -1.6111, -0.7057],\n",
      "          [-1.2946, -0.8410, -2.2760,  ..., -1.2205, -1.0586, -0.9070]],\n",
      "\n",
      "         [[-1.2549, -2.6272, -1.7629,  ..., -0.6698, -1.1612, -1.0135],\n",
      "          [-1.2049, -1.3192, -1.8954,  ..., -1.5626, -1.7784, -2.3894],\n",
      "          [-1.0648, -1.9508, -1.3273,  ..., -1.4205, -1.2373, -2.0314],\n",
      "          ...,\n",
      "          [-1.3030, -1.6343, -1.5093,  ..., -0.6218, -1.4762, -1.2509],\n",
      "          [-2.0331, -1.4507, -1.5842,  ..., -1.0148, -1.4738, -1.7831],\n",
      "          [-1.4600, -1.3772, -1.0569,  ..., -1.6816, -1.3310, -1.3490]],\n",
      "\n",
      "         [[-3.1888, -2.5809, -1.0430,  ..., -1.4705, -1.5559, -1.4845],\n",
      "          [-1.9813, -2.0327, -1.9258,  ..., -1.7430, -2.2729, -1.7425],\n",
      "          [-2.4345, -1.7415, -1.3797,  ..., -1.2387, -1.2444, -1.3021],\n",
      "          ...,\n",
      "          [-1.7160, -0.7276, -2.2139,  ..., -1.3713, -2.4001, -1.7891],\n",
      "          [-1.5002, -1.4088, -1.2380,  ..., -0.7715, -1.1788, -1.6466],\n",
      "          [-1.5866, -1.8663, -1.8416,  ..., -1.2382, -1.5278, -1.5705]]],\n",
      "\n",
      "\n",
      "        [[[-1.4663, -0.7726, -1.8431,  ..., -1.6667, -2.1250, -1.3027],\n",
      "          [-2.0807, -1.9133, -1.1985,  ..., -1.5329, -1.7574, -1.3951],\n",
      "          [-1.1277, -1.7046, -0.8433,  ..., -1.7188, -2.1530, -2.3773],\n",
      "          ...,\n",
      "          [-1.3736, -1.2421, -1.8447,  ..., -1.2501, -1.5120, -1.9293],\n",
      "          [-0.4960, -1.4354, -1.6526,  ..., -0.6559, -1.4869, -0.6619],\n",
      "          [-1.1969, -1.6192, -1.6487,  ..., -2.1404, -1.1027, -1.6072]],\n",
      "\n",
      "         [[-1.2927, -1.6513, -0.6660,  ..., -1.4599, -1.7067, -1.3190],\n",
      "          [-1.5448, -1.3255, -1.4368,  ..., -1.3442, -0.4642, -1.6707],\n",
      "          [-1.2243, -1.5378, -2.3743,  ..., -0.7561, -2.0774, -1.3744],\n",
      "          ...,\n",
      "          [-1.3349, -1.5075, -1.1328,  ..., -1.9225, -1.0421, -1.4679],\n",
      "          [-1.6860, -1.9796, -1.6422,  ..., -1.6238, -1.4245, -1.7613],\n",
      "          [-1.3334, -1.1896, -0.9986,  ..., -1.6298, -1.1434, -1.1749]],\n",
      "\n",
      "         [[-2.2709, -1.6473, -1.6669,  ..., -1.0586, -0.4900, -1.2732],\n",
      "          [-1.4384, -1.3439, -1.9441,  ..., -1.3367, -2.2134, -0.9984],\n",
      "          [-2.0968, -1.0231, -1.1190,  ..., -1.5973, -0.7945, -0.9176],\n",
      "          ...,\n",
      "          [-1.9129, -1.3840, -1.1398,  ..., -1.6716, -1.3737, -1.2308],\n",
      "          [-2.8405, -1.7107, -1.3830,  ..., -1.8992, -1.0119, -2.0650],\n",
      "          [-1.4808, -1.0137, -1.2443,  ..., -0.7550, -1.4208, -1.0228]],\n",
      "\n",
      "         [[-0.9378, -1.8722, -1.9727,  ..., -1.4612, -2.4482, -1.7101],\n",
      "          [-0.8568, -1.1211, -1.1471,  ..., -1.3446, -2.4131, -1.6318],\n",
      "          [-1.3493, -1.4114, -1.8969,  ..., -1.9052, -1.1816, -1.3676],\n",
      "          ...,\n",
      "          [-1.0907, -1.4305, -1.6099,  ..., -0.9693, -1.7507, -1.1018],\n",
      "          [-1.9149, -0.8139, -1.0104,  ..., -2.0087, -1.7733, -1.6846],\n",
      "          [-1.5758, -2.0046, -1.8894,  ..., -1.5305, -2.2279, -2.0316]]],\n",
      "\n",
      "\n",
      "        [[[-1.2769, -1.7222, -1.5933,  ..., -1.9398, -1.4289, -1.3443],\n",
      "          [-1.8904, -2.4146, -2.0246,  ..., -1.2808, -2.0660, -1.1579],\n",
      "          [-1.2284, -1.6335, -1.8245,  ..., -1.5686, -2.2088, -2.3105],\n",
      "          ...,\n",
      "          [-1.0446, -1.0113, -1.4937,  ..., -1.3860, -1.2573, -1.6600],\n",
      "          [-0.8342, -1.2628, -1.9749,  ..., -1.7262, -1.8658, -1.7925],\n",
      "          [-1.4965, -1.7667, -2.1953,  ..., -2.5234, -1.0194, -1.2282]],\n",
      "\n",
      "         [[-0.9109, -0.9597, -0.8970,  ..., -0.3976, -1.9934, -2.3613],\n",
      "          [-2.2048, -1.9307, -0.9237,  ..., -2.0444, -1.1379, -0.8709],\n",
      "          [-0.9419, -1.0896, -1.7108,  ..., -1.2270, -0.9144, -1.0265],\n",
      "          ...,\n",
      "          [-0.7904, -1.3291, -1.9064,  ..., -0.9275, -1.0063, -1.5315],\n",
      "          [-2.2299, -0.7169, -0.9651,  ..., -2.4501, -1.6554, -1.4375],\n",
      "          [-1.1776, -0.7007, -0.8160,  ..., -0.7509, -1.5503, -1.6621]],\n",
      "\n",
      "         [[-2.1058, -2.3382, -2.0160,  ..., -2.6237, -0.7230, -0.9989],\n",
      "          [-1.1634, -1.0162, -2.0031,  ..., -1.2579, -1.2376, -1.6498],\n",
      "          [-1.8489, -1.5464, -1.0708,  ..., -1.5622, -1.3015, -0.8509],\n",
      "          ...,\n",
      "          [-2.6046, -2.4177, -1.4353,  ..., -2.0983, -1.8096, -0.9828],\n",
      "          [-1.5484, -2.2338, -1.2309,  ..., -0.5308, -0.8899, -1.0597],\n",
      "          [-1.3524, -1.9044, -1.0978,  ..., -0.9980, -1.3723, -1.5420]],\n",
      "\n",
      "         [[-1.6235, -1.0735, -1.3636,  ..., -2.1908, -1.9742, -1.2848],\n",
      "          [-0.8526, -0.9074, -1.0907,  ..., -1.1761, -1.3366, -2.5878],\n",
      "          [-1.8331, -1.3650, -1.1544,  ..., -1.2419, -1.5265, -2.1587],\n",
      "          ...,\n",
      "          [-2.1156, -1.2644, -0.9447,  ..., -1.4622, -1.6804, -1.5170],\n",
      "          [-1.4038, -2.1059, -1.6699,  ..., -1.9130, -1.4127, -1.3887],\n",
      "          [-1.5633, -1.6932, -2.1816,  ..., -2.5349, -1.7518, -1.1924]]]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "1.51111900806427\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method Tensor.backward of tensor(1.5111, grad_fn=<NllLoss2DBackward>)>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = nn.LogSoftmax(dim=1)\n",
    "loss = nn.NLLLoss()\n",
    "# input is of size N x C = 3 x 5\n",
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "# each element in target has to have 0 <= value < C\n",
    "target = torch.tensor([1, 0, 4])\n",
    "output = loss(m(input), target)\n",
    "output.backward()\n",
    "\n",
    "\n",
    "# 2D loss example (used, for example, with image inputs)\n",
    "N, C = 5, 4\n",
    "loss = nn.NLLLoss()\n",
    "# input is of size N x C x height x width\n",
    "data = torch.randn(N, 16, 10, 10)\n",
    "conv = nn.Conv2d(16, C, (3, 3))\n",
    "m = nn.LogSoftmax(dim=1)\n",
    "# each element in target has to have 0 <= value < C\n",
    "target = torch.empty(N, 8, 8, dtype=torch.long).random_(0, C)\n",
    "output = loss(m(conv(data)), target)\n",
    "print(target)\n",
    "print(m(conv(data)))\n",
    "print(output.item())\n",
    "output.backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "useful-connection",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-friend",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gothic-interval",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liable-horror",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excited-victory",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "japanese-confidence",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "owned-assist",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "packed-laser",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
