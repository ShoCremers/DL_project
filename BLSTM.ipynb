{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "prerequisite-subscription",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup dependencies (as taken from assignment 6)\n",
    "import os\n",
    "import math\n",
    "from collections import OrderedDict\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, transforms, models\n",
    "\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "from joblib import load\n",
    "\n",
    "from pytorch_forecasting.metrics import QuantileLoss\n",
    "\n",
    "#Additional Setup to use Tensorboard\n",
    "!pip install -q tensorflow\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "proprietary-equilibrium",
   "metadata": {},
   "outputs": [],
   "source": [
    "dayahead_scaler = load('dayahead_scaler.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "premium-equipment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day-ahead Price [EUR/MWh]</th>\n",
       "      <th>tempC</th>\n",
       "      <th>windspeedKmph</th>\n",
       "      <th>winddirDegree</th>\n",
       "      <th>precipMM</th>\n",
       "      <th>humidity</th>\n",
       "      <th>pressure</th>\n",
       "      <th>time_increment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-01-05 00:00:00</th>\n",
       "      <td>-0.243620</td>\n",
       "      <td>-1.722376</td>\n",
       "      <td>-0.422598</td>\n",
       "      <td>0.563889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.96</td>\n",
       "      <td>2.163731</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-05 01:00:00</th>\n",
       "      <td>-0.316395</td>\n",
       "      <td>-1.722376</td>\n",
       "      <td>-0.297098</td>\n",
       "      <td>0.572222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.96</td>\n",
       "      <td>2.058525</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-05 02:00:00</th>\n",
       "      <td>-0.439933</td>\n",
       "      <td>-1.722376</td>\n",
       "      <td>-0.171598</td>\n",
       "      <td>0.580556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.96</td>\n",
       "      <td>2.058525</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-05 03:00:00</th>\n",
       "      <td>-0.625914</td>\n",
       "      <td>-1.722376</td>\n",
       "      <td>-0.046098</td>\n",
       "      <td>0.588889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.953318</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-01-05 04:00:00</th>\n",
       "      <td>-0.626363</td>\n",
       "      <td>-1.722376</td>\n",
       "      <td>-0.171598</td>\n",
       "      <td>0.575000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.953318</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31 19:00:00</th>\n",
       "      <td>0.877205</td>\n",
       "      <td>-1.130468</td>\n",
       "      <td>-0.673599</td>\n",
       "      <td>0.602778</td>\n",
       "      <td>0.054545</td>\n",
       "      <td>0.94</td>\n",
       "      <td>-1.728907</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31 20:00:00</th>\n",
       "      <td>0.665169</td>\n",
       "      <td>-1.130468</td>\n",
       "      <td>-0.422598</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>0.93</td>\n",
       "      <td>-1.728907</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31 21:00:00</th>\n",
       "      <td>0.469755</td>\n",
       "      <td>-1.130468</td>\n",
       "      <td>-0.171598</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.054545</td>\n",
       "      <td>0.93</td>\n",
       "      <td>-1.623701</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31 22:00:00</th>\n",
       "      <td>0.443699</td>\n",
       "      <td>-1.278445</td>\n",
       "      <td>-0.422598</td>\n",
       "      <td>0.747222</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>0.92</td>\n",
       "      <td>-1.413288</td>\n",
       "      <td>2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-31 23:00:00</th>\n",
       "      <td>0.461668</td>\n",
       "      <td>-1.426422</td>\n",
       "      <td>-0.673599</td>\n",
       "      <td>0.847222</td>\n",
       "      <td>0.018182</td>\n",
       "      <td>0.91</td>\n",
       "      <td>-1.308081</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52512 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Day-ahead Price [EUR/MWh]     tempC  windspeedKmph  \\\n",
       "datetime                                                                  \n",
       "2015-01-05 00:00:00                  -0.243620 -1.722376      -0.422598   \n",
       "2015-01-05 01:00:00                  -0.316395 -1.722376      -0.297098   \n",
       "2015-01-05 02:00:00                  -0.439933 -1.722376      -0.171598   \n",
       "2015-01-05 03:00:00                  -0.625914 -1.722376      -0.046098   \n",
       "2015-01-05 04:00:00                  -0.626363 -1.722376      -0.171598   \n",
       "...                                        ...       ...            ...   \n",
       "2020-12-31 19:00:00                   0.877205 -1.130468      -0.673599   \n",
       "2020-12-31 20:00:00                   0.665169 -1.130468      -0.422598   \n",
       "2020-12-31 21:00:00                   0.469755 -1.130468      -0.171598   \n",
       "2020-12-31 22:00:00                   0.443699 -1.278445      -0.422598   \n",
       "2020-12-31 23:00:00                   0.461668 -1.426422      -0.673599   \n",
       "\n",
       "                     winddirDegree  precipMM  humidity  pressure  \\\n",
       "datetime                                                           \n",
       "2015-01-05 00:00:00       0.563889  0.000000      0.96  2.163731   \n",
       "2015-01-05 01:00:00       0.572222  0.000000      0.96  2.058525   \n",
       "2015-01-05 02:00:00       0.580556  0.000000      0.96  2.058525   \n",
       "2015-01-05 03:00:00       0.588889  0.000000      0.96  1.953318   \n",
       "2015-01-05 04:00:00       0.575000  0.000000      0.96  1.953318   \n",
       "...                            ...       ...       ...       ...   \n",
       "2020-12-31 19:00:00       0.602778  0.054545      0.94 -1.728907   \n",
       "2020-12-31 20:00:00       0.625000  0.036364      0.93 -1.728907   \n",
       "2020-12-31 21:00:00       0.650000  0.054545      0.93 -1.623701   \n",
       "2020-12-31 22:00:00       0.747222  0.036364      0.92 -1.413288   \n",
       "2020-12-31 23:00:00       0.847222  0.018182      0.91 -1.308081   \n",
       "\n",
       "                     time_increment  \n",
       "datetime                             \n",
       "2015-01-05 00:00:00             2.4  \n",
       "2015-01-05 01:00:00             0.1  \n",
       "2015-01-05 02:00:00             0.2  \n",
       "2015-01-05 03:00:00             0.3  \n",
       "2015-01-05 04:00:00             0.4  \n",
       "...                             ...  \n",
       "2020-12-31 19:00:00             1.9  \n",
       "2020-12-31 20:00:00             2.0  \n",
       "2020-12-31 21:00:00             2.1  \n",
       "2020-12-31 22:00:00             2.2  \n",
       "2020-12-31 23:00:00             2.3  \n",
       "\n",
       "[52512 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('day_ahead.csv')\n",
    "df = df.set_index('datetime')\n",
    "df.index = pd.to_datetime(df.index)\n",
    "# df=df[\"Day-ahead Price [EUR/MWh]\"].to_frame()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "english-beast",
   "metadata": {},
   "source": [
    "# Create Torch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "recognized-aging",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequence length (edit the value for different sequence length)\n",
    "seq = 24 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "velvet-thunder",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = pd.Timedelta(seq, unit ='h')\n",
    "# define 1 hour object for convenience when using datetime as index in the dataframe to not include the last item\n",
    "hours_12 = pd.Timedelta(12, unit ='h') # used mostly for empty 12 hours \n",
    "hour = pd.Timedelta(1, unit ='h')\n",
    "day = pd.Timedelta(1, unit ='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "flush-crawford",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2125, 24, 8)\n",
      "(2125, 24)\n"
     ]
    }
   ],
   "source": [
    "### creating training dataset\n",
    "train_y_start = dt.datetime(2015, 1, 5, 0, 0) + (delta+hours_12).ceil('1d')\n",
    "#train_x_start = train_y_start - delta - hours_12\n",
    "train_end = dt.datetime(2020, 10, 31, 23, 0)\n",
    "\n",
    "train_x = []\n",
    "train_y = []\n",
    "while train_y_start + day - hour <= train_end:\n",
    "    train_x_start = train_y_start - delta - hours_12\n",
    "    \n",
    "    \n",
    "    #print(train_x_start, train_y_start)\n",
    "    train_x.append(df[train_x_start:train_x_start+delta - hour].values)\n",
    "    train_y.append(df[train_y_start:train_y_start+day - hour]['Day-ahead Price [EUR/MWh]'].values)\n",
    "    \n",
    "    train_y_start += day\n",
    "    \n",
    "train_x = np.asarray(train_x)\n",
    "train_y = np.asarray(train_y)\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "# print(train_x)\n",
    "# print(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "identified-assets",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 24, 8)\n",
      "(30, 24)\n"
     ]
    }
   ],
   "source": [
    "### creating validation dataset\n",
    "val_y_start = dt.datetime(2020, 11, 1, 0, 0)\n",
    "val_end = dt.datetime(2020, 11, 30, 23, 0)\n",
    "\n",
    "val_x = []\n",
    "val_y = []\n",
    "while val_y_start + day - hour <= val_end:\n",
    "    val_x_start = val_y_start - delta - hours_12\n",
    "    \n",
    "    val_x.append(df[val_x_start:val_x_start+delta - hour].values)\n",
    "    val_y.append(df[val_y_start:val_y_start+day - hour]['Day-ahead Price [EUR/MWh]'].values)\n",
    "    \n",
    "    val_y_start += day\n",
    "\n",
    "val_x = np.asarray(val_x)\n",
    "val_y = np.asarray(val_y)\n",
    "print(val_x.shape)\n",
    "print(val_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "demanding-copyright",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31, 24, 8)\n",
      "(31, 24)\n"
     ]
    }
   ],
   "source": [
    "### creating testing dataset\n",
    "test_y_start = dt.datetime(2020, 12, 1, 0, 0)\n",
    "test_end = dt.datetime(2020, 12, 31, 23, 0)\n",
    "\n",
    "test_x = []\n",
    "test_y = []\n",
    "while test_y_start + day - hour <= test_end:\n",
    "    test_x_start = test_y_start - delta - hours_12\n",
    "    \n",
    "    test_x.append(df[test_x_start:test_x_start+delta - hour].values)\n",
    "    test_y.append(df[test_y_start:test_y_start+day - hour]['Day-ahead Price [EUR/MWh]'].values)\n",
    "    \n",
    "    test_y_start += day\n",
    "\n",
    "test_x = np.asarray(test_x)\n",
    "test_y = np.asarray(test_y)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "taken-somalia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tensor objects\n",
    "x_train = torch.from_numpy(train_x).float()\n",
    "y_train = torch.from_numpy(train_y).float()\n",
    "x_val = torch.from_numpy(val_x).float()\n",
    "y_val = torch.from_numpy(val_y).float()\n",
    "x_test = torch.from_numpy(test_x).float()\n",
    "y_test = torch.from_numpy(test_y).float()\n",
    "# train_loader = DataLoader(x_train,y_train, batch_size=128, shuffle=False)\n",
    "# val_loader = DataLoader(x_test,y_test batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "muslim-blame",
   "metadata": {},
   "source": [
    "# Define BLSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "rural-activation",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim, quantiles):\n",
    "        super(BLSTM, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, bidirectional=True)\n",
    "#         self.fc = nn.Linear(hidden_dim*2, output_dim) # multiply hidden_dim by 2 because bidirectional\n",
    "        \n",
    "        self.quantiles = quantiles\n",
    "        self.num_quantiles = len(quantiles)\n",
    "        self.out_shape = len(quantiles)\n",
    "        \n",
    "        final_layers = [\n",
    "            nn.Linear(hidden_dim*2, output_dim) for _ in range(len(self.quantiles))\n",
    "        ]\n",
    "        self.final_layers = nn.ModuleList(final_layers)\n",
    "        \n",
    "    def add_noise_to_weights(self):\n",
    "        with torch.no_grad():\n",
    "            # add noise to lstm weights\n",
    "            for weights in model.lstm._all_weights:\n",
    "                for weight in weights:\n",
    "                    noise = torch.normal(0, 0.01, size=self.lstm._parameters[weight].size())\n",
    "                    self.lstm._parameters[weight].add_(noise)\n",
    "            # add noise to linear layer weights, most likely unnecessary\n",
    "#             for layer in self.final_layers:\n",
    "#                 if hasattr(layer, 'weight'):\n",
    "#                     noise = torch.normal(0, 0.05, size=layer.weight.size())\n",
    "#                     layer.weight.add_(noise)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_dim).requires_grad_() #hidden layer output\n",
    "        # Initialize cell state\n",
    "        c0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_dim).requires_grad_() \n",
    "        # We need to detach as we are doing truncated backpropagation through time (BPTT)\n",
    "        # If we don't, we'll backprop all the way to the start even after going through another batch\n",
    "        out, (hn, cn) = self.lstm(x, (h0.detach(), c0.detach()))\n",
    "        # Index hidden state of last time step\n",
    "#         _out = self.fc(out[:, -1, :])\n",
    "        \n",
    "        return torch.stack([layer(out[:, -1, :]) for layer in self.final_layers], dim=1)\n",
    "        \n",
    "        \n",
    "#         return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fuzzy-thompson",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "automated-valuation",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = x_train.shape[0]\n",
    "input_dim = x_train.shape[2]\n",
    "output_dim = 24 \n",
    "hidden_dim = 10 # no. of neurons in hidden layer\n",
    "num_layers = 2 # no of hidden layers \n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "dress-respect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLSTM(\n",
      "  (lstm): LSTM(8, 10, num_layers=2, batch_first=True, bidirectional=True)\n",
      "  (final_layers): ModuleList(\n",
      "    (0): Linear(in_features=20, out_features=24, bias=True)\n",
      "    (1): Linear(in_features=20, out_features=24, bias=True)\n",
      "    (2): Linear(in_features=20, out_features=24, bias=True)\n",
      "    (3): Linear(in_features=20, out_features=24, bias=True)\n",
      "    (4): Linear(in_features=20, out_features=24, bias=True)\n",
      "    (5): Linear(in_features=20, out_features=24, bias=True)\n",
      "    (6): Linear(in_features=20, out_features=24, bias=True)\n",
      "    (7): Linear(in_features=20, out_features=24, bias=True)\n",
      "    (8): Linear(in_features=20, out_features=24, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "quantiles = [.01,0.05, 0.10,0.25, .5, 0.75, 0.90, 0.95, .99]\n",
    "criterion = QuantileLoss(quantiles)\n",
    "\n",
    "model = BLSTM(input_dim=input_dim, hidden_dim=hidden_dim, output_dim=output_dim, num_layers=num_layers, quantiles=quantiles)\n",
    "# for practice use MSE, in real experiment use NLLLOSS for parametric\n",
    "print(model)\n",
    "\n",
    "#criterion = nn.NLLLoss()\n",
    "optimiser = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "favorite-reunion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 training loss:  0.9636192497646108 validation loss:  0.8346549272537231\n",
      "Epoch  2 training loss:  0.9244497227809009 validation loss:  0.8262961506843567\n",
      "Epoch  3 training loss:  0.9006396905674654 validation loss:  0.8178761005401611\n",
      "Epoch  4 training loss:  0.8909461239926956 validation loss:  0.8041594624519348\n",
      "Epoch  5 training loss:  0.8909279234970318 validation loss:  0.791286826133728\n",
      "Epoch  6 training loss:  0.8832045979359571 validation loss:  0.8540537357330322\n",
      "Epoch  7 training loss:  0.8819951967632069 validation loss:  0.8032194972038269\n",
      "Epoch  8 training loss:  0.8777909570020788 validation loss:  0.7955278754234314\n",
      "Epoch  9 training loss:  0.874993094850989 validation loss:  0.8108619451522827\n",
      "Epoch  10 training loss:  0.8718469272501328 validation loss:  0.8154060244560242\n",
      "Early stopping\n"
     ]
    }
   ],
   "source": [
    "# Patience - how many epochs to keep training after accuracy has not improved\n",
    "patience = 5\n",
    "\n",
    "# Initialize early stopping variables\n",
    "val_loss_best = np.Inf\n",
    "patience_cnt = 0\n",
    "\n",
    "# training loop\n",
    "val_losses = []\n",
    "for t in range(num_epochs): \n",
    "    err = 0\n",
    "    for i in range(num_train):\n",
    "        model.add_noise_to_weights() # adding noise to lstm weights during the training\n",
    "        y_train_pred = model(x_train[i].unsqueeze(0))\n",
    "\n",
    "        loss = torch.mean(torch.sum(criterion.loss(torch.transpose(y_train_pred,1,2), y_train[i]), dim=2))\n",
    "        optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        err += loss.item()\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        preds=model(x_val)\n",
    "        val_loss = torch.mean(torch.sum(criterion.loss(torch.transpose(preds,1,2), y_val), dim=2)).item()\n",
    "        val_losses.append(val_loss)\n",
    "    \n",
    "    print(\"Epoch \", t+1, \"training loss: \", err/num_train, \"validation loss: \", val_loss)\n",
    "    \n",
    "    if val_loss < val_loss_best:\n",
    "        val_loss_best = val_loss\n",
    "        patience_cnt = 0\n",
    "    else:\n",
    "        patience_cnt +=1\n",
    "        if patience_cnt == patience:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "associate-scheme",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = np.arange(1, len(val_losses)+1)\n",
    "plt.plot(X, val_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "thrown-welcome",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the prediction on the meshed x-axis\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    preds=model(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "laden-retail",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = dayahead_scaler.inverse_transform(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "wooden-reservation",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = df[dt.datetime(2020, 12, 1, 0, 0):dt.datetime(2020, 12, 31, 23, 0)][['Day-ahead Price [EUR/MWh]']]\n",
    "test_df[test_df.columns] = dayahead_scaler.inverse_transform(test_df.values)\n",
    "for i in range(preds.shape[1]):\n",
    "    y=preds[:,i,:]\n",
    "    test_df[str(i)]=y.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "remarkable-american",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.715593681598495"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_test = torch.from_numpy(np.transpose(preds,(0,2,1)))\n",
    "y_test_price = torch.from_numpy(test_df['Day-ahead Price [EUR/MWh]'].values.reshape((-1, 24)))\n",
    "\n",
    "# quantile loss in term of dayahead price (not normalize or standardize)\n",
    "torch.mean(torch.sum(criterion.loss(preds_test, y_test_price), dim=2)).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "configured-wisdom",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_df.plot()    \n",
    "\n",
    "# y_lower, y_pred, y_upper = preds[:, 0,:], preds[:, 1,:], preds[:, 2,:],\n",
    "# print(y_lower.shape)\n",
    "\n",
    "\n",
    "# test_df['q1'] = y_lower.flatten()\n",
    "# test_df['q2'] = y_pred.flatten()\n",
    "# test_df['q3'] = y_upper.flatten()\n",
    "# test_df.plot();\n",
    "\n",
    "\n",
    "# Plot the function, the prediction and the 90% confidence interval based on\n",
    "# # the MSE\n",
    "# fig = plt.figure()\n",
    "# plt.plot(xx, f(xx), 'g:', label=u'$f(x) = x\\,\\sin(x)$')\n",
    "# plt.plot(X, y, 'b.', markersize=10, label=u'Observations')\n",
    "# plt.plot(xx, y_pred, 'r-', label=u'Prediction')\n",
    "# plt.plot(xx, y_upper, 'k-')\n",
    "# plt.plot(xx, y_lower, 'k-')\n",
    "# plt.fill(np.concatenate([xx, xx[::-1]]),\n",
    "#          np.concatenate([y_upper, y_lower[::-1]]),\n",
    "#          alpha=.5, fc='b', ec='None', label='90% prediction interval')\n",
    "# plt.xlabel('$x$')\n",
    "# plt.ylabel('$f(x)$')\n",
    "# plt.ylim(-10, 20)\n",
    "# plt.legend(loc='upper left')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dangerous-criterion",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filled-tucson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot whole data\n",
    "\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.plot(test_df.index, test_df['Day-ahead Price [EUR/MWh]'].values, 'r', label='expected')\n",
    "\n",
    "plt.fill(np.concatenate([test_df.index, test_df.index[::-1]]),\n",
    "         np.concatenate([test_df['8'].values.flatten(), test_df['0'].values.flatten()]),\n",
    "         alpha=.25, fc='grey', ec='None', label='98% prediction interval')\n",
    "\n",
    "plt.fill(np.concatenate([test_df.index, test_df.index[::-1]]),\n",
    "         np.concatenate([test_df['7'].values.flatten(), test_df['1'].values.flatten()]),\n",
    "         alpha=.5, fc='grey', ec='None', label='90% prediction interval')\n",
    "\n",
    "plt.fill(np.concatenate([test_df.index, test_df.index[::-1]]),\n",
    "         np.concatenate([test_df['6'].values.flatten(), test_df['2'].values.flatten()]),\n",
    "         alpha=.75, fc='grey', ec='None', label='80% prediction interval')\n",
    "\n",
    "plt.fill(np.concatenate([test_df.index, test_df.index[::-1]]),\n",
    "         np.concatenate([test_df['5'].values.flatten(), test_df['3'].values.flatten()]),\n",
    "         alpha=0.9, fc='grey', ec='None', label='50% prediction interval')\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Day ahead Price')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-mapping",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot first 7 days\n",
    "\n",
    "part_df = test_df[dt.datetime(2020, 12, 1, 0, 0):dt.datetime(2020, 12, 8, 0, 0)]\n",
    "part_df\n",
    "\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "plt.plot(part_df.index, part_df['Day-ahead Price [EUR/MWh]'].values, 'r', label='expected')\n",
    "\n",
    "plt.fill(np.concatenate([part_df.index, part_df.index[::-1]]),\n",
    "         np.concatenate([part_df['8'].values.flatten(), part_df['0'].values.flatten()]),\n",
    "         alpha=.25, fc='grey', ec='None', label='98% prediction interval')\n",
    "\n",
    "plt.fill(np.concatenate([part_df.index, part_df.index[::-1]]),\n",
    "         np.concatenate([part_df['7'].values.flatten(), part_df['1'].values.flatten()]),\n",
    "         alpha=.5, fc='grey', ec='None', label='90% prediction interval')\n",
    "\n",
    "plt.fill(np.concatenate([part_df.index, part_df.index[::-1]]),\n",
    "         np.concatenate([part_df['6'].values.flatten(), part_df['2'].values.flatten()]),\n",
    "         alpha=.75, fc='grey', ec='None', label='80% prediction interval')\n",
    "\n",
    "plt.fill(np.concatenate([part_df.index, part_df.index[::-1]]),\n",
    "         np.concatenate([part_df['5'].values.flatten(), part_df['3'].values.flatten()]),\n",
    "         alpha=0.9, fc='grey', ec='None', label='50% prediction interval')\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Day ahead Price')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decent-mobility",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dangerous-european",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "useful-connection",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-friend",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
